{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import json, gzip\n",
    "import random as rnd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "from IPython.display import display, HTML\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName = '<dictionary_file_name>'\n",
    "reader = open(fileName, 'rU')\n",
    "vocabulary = {}\n",
    "counter = 0\n",
    "for line in reader:\n",
    "    vocabulary[int(line.strip())] = counter \n",
    "    counter = counter + 1\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "document = []\n",
    "fileName = '<documents_file_name>'\n",
    "reader = open(fileName, 'rU')\n",
    "ldocid = -1l\n",
    "for line in reader:\n",
    "    tokens = line.strip().split(',')\n",
    "    docid = int(tokens[0])\n",
    "    word = int(tokens[1])\n",
    "    wordIndex = vocabulary[word]\n",
    "    if ldocid != -1l and docid != ldocid:\n",
    "        documents.append(document)\n",
    "        doc = []\n",
    "    doc.append(wordIndex)\n",
    "    ldocid = docid\n",
    "documents.append(doc)\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5250, 100000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary),len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultinomialMixture :\n",
    "    def __init__(self, num_clusters, vocabulary_size):\n",
    "        self.multinomials = np.zeros((vocabulary_size, num_clusters))\n",
    "        self.proportions = np.zeros(num_clusters)\n",
    "        self.num_clusters = num_clusters\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        for w in range(vocabulary_size):\n",
    "            for k in range(num_clusters):\n",
    "                self.multinomials[w, k] = rnd.uniform(0,1)\n",
    "        \n",
    "        for k in range(num_clusters):\n",
    "            self.multinomials[:, k] /= self.multinomials[:, k].sum()\n",
    "            self.proportions[k]  = rnd.uniform(0, 1)\n",
    "        self.proportions /= self.proportions.sum()\n",
    "        \n",
    "    def compute_multinomial_responsibilities(self, doc):\n",
    "        \n",
    "        q_zn = np.zeros(self.num_clusters)\n",
    "        q_zn += self.proportions\n",
    "        \n",
    "        for v in doc:\n",
    "            q_zn *= self.multinomials[v, :]\n",
    "            q_zn /= max(q_zn)\n",
    "        \n",
    "        return q_zn / q_zn.sum()\n",
    "    \n",
    "    def compute_multinomial_responsibilities_with_lb(self, doc):\n",
    "        \n",
    "        q_zn = np.zeros(self.num_clusters)\n",
    "        q_zn += self.proportions\n",
    "        log_cumulative_scale = 0\n",
    "        for v in doc:\n",
    "            q_zn *= self.multinomials[v, :]\n",
    "            scale =  max(q_zn)\n",
    "            log_cumulative_scale += log(scale)\n",
    "            q_zn /= scale\n",
    "        \n",
    "        normalizer = q_zn.sum()\n",
    "        return (q_zn / normalizer, log(normalizer) + log_cumulative_scale)\n",
    "        \n",
    "    def compute_lower_bound(self, q_zn, doc):\n",
    "        valid_ind = q_zn > 0\n",
    "        entropy = q_zn[valid_ind].dot(q_zn[valid_ind])\n",
    "        comp1 = q_zn.dot(log(self.proportions))\n",
    "        comp2 = 0\n",
    "        for v in doc:\n",
    "            likelihood_v = self.multinomials[v, :]\n",
    "            valid_ind = likelihood_v > 0\n",
    "            comp2 += q_zn[valid_ind].dot(log(likelihood_v[valid_ind]))\n",
    "    \n",
    "        return comp1 + comp2 - entropy\n",
    "    \n",
    "    def fit(self, documents, max_iter):\n",
    "        aggregates = np.zeros((self.vocabulary_size, self.num_clusters))\n",
    "        prop_aggregates = np.zeros(self.num_clusters)\n",
    "        lower_bounds = []\n",
    "        q_zn = np.zeros(self.num_clusters)\n",
    "        for iteration in range(max_iter):\n",
    "            lower_bound = 0\n",
    "            start = time.time()\n",
    "            for doc in documents:\n",
    "                q_zn, lb = self.compute_multinomial_responsibilities_with_lb(doc)\n",
    "                lower_bound += lb\n",
    "                aggregates[doc, :] += q_zn\n",
    "                prop_aggregates += q_zn\n",
    "            \n",
    "            self.proportions = prop_aggregates / prop_aggregates.sum()\n",
    "            for k in range(self.num_clusters):\n",
    "                self.multinomials[:, k] = aggregates[:, k] / (aggregates[:, k].sum())\n",
    "            aggregates *= 0\n",
    "            prop_aggregates *= 0\n",
    "            lower_bounds.append(lower_bound)\n",
    "            end = time.time()\n",
    "            duration = end - start\n",
    "            print 'iter:%d,lower_bound:%f,duration:%f secs'%(iteration, lower_bound,duration)\n",
    "            sys.stdout.flush()\n",
    "        return lower_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_clusters = 100\n",
    "multinomial_mixture_model = MultinomialMixture(num_clusters, len(vocabulary))\n",
    "lower_bounds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower_bounds_1 = multinomial_mixture_model.fit(documents, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0,lower_bound:-34550925.735975,duration:85.082673 secs\n",
      "iter:1,lower_bound:-34550615.967011,duration:84.855282 secs\n",
      "iter:2,lower_bound:-34550318.418235,duration:85.159552 secs\n",
      "iter:3,lower_bound:-34550043.398711,duration:85.443403 secs\n",
      "iter:4,lower_bound:-34549810.265726,duration:85.007944 secs\n",
      "iter:5,lower_bound:-34549515.501112,duration:84.793148 secs\n",
      "iter:6,lower_bound:-34549295.727313,duration:84.945006 secs\n",
      "iter:7,lower_bound:-34549074.747334,duration:88.487706 secs\n",
      "iter:8,lower_bound:-34548929.190622,duration:107.211903 secs\n",
      "iter:9,lower_bound:-34548707.507324,duration:104.724047 secs\n",
      "iter:10,lower_bound:-34548574.068746,duration:94.439614 secs\n",
      "iter:11,lower_bound:-34548441.187247,duration:85.012167 secs\n",
      "iter:12,lower_bound:-34548312.345733,duration:85.022323 secs\n",
      "iter:13,lower_bound:-34548163.888608,duration:85.250630 secs\n",
      "iter:14,lower_bound:-34548041.801027,duration:84.922757 secs\n",
      "iter:15,lower_bound:-34547902.990646,duration:85.022633 secs\n",
      "iter:16,lower_bound:-34547756.818694,duration:85.578202 secs\n",
      "iter:17,lower_bound:-34547623.003781,duration:85.031899 secs\n",
      "iter:18,lower_bound:-34547498.212597,duration:84.866341 secs\n",
      "iter:19,lower_bound:-34547416.178296,duration:85.186124 secs\n",
      "iter:20,lower_bound:-34547319.164473,duration:84.991416 secs\n",
      "iter:21,lower_bound:-34547226.437020,duration:84.883367 secs\n",
      "iter:22,lower_bound:-34547141.071863,duration:85.218802 secs\n",
      "iter:23,lower_bound:-34547062.844670,duration:84.831297 secs\n",
      "iter:24,lower_bound:-34546962.677391,duration:85.211147 secs\n",
      "iter:25,lower_bound:-34546852.987544,duration:84.921793 secs\n",
      "iter:26,lower_bound:-34546740.541243,duration:85.279118 secs\n",
      "iter:27,lower_bound:-34546663.793647,duration:85.456988 secs\n",
      "iter:28,lower_bound:-34546606.878701,duration:85.205101 secs\n",
      "iter:29,lower_bound:-34546541.771541,duration:84.880953 secs\n",
      "iter:30,lower_bound:-34546480.457632,duration:85.236723 secs\n",
      "iter:31,lower_bound:-34546408.614855,duration:84.743989 secs\n",
      "iter:32,lower_bound:-34546335.251335,duration:85.050682 secs\n",
      "iter:33,lower_bound:-34546291.359743,duration:85.068763 secs\n",
      "iter:34,lower_bound:-34546208.614315,duration:85.117170 secs\n",
      "iter:35,lower_bound:-34546154.609894,duration:85.052020 secs\n",
      "iter:36,lower_bound:-34546079.444739,duration:85.486430 secs\n",
      "iter:37,lower_bound:-34546015.904222,duration:85.130009 secs\n",
      "iter:38,lower_bound:-34545930.737721,duration:84.681244 secs\n",
      "iter:39,lower_bound:-34545863.682048,duration:85.130596 secs\n",
      "iter:40,lower_bound:-34545807.343195,duration:84.671151 secs\n",
      "iter:41,lower_bound:-34545737.097788,duration:84.997836 secs\n",
      "iter:42,lower_bound:-34545694.334343,duration:86.761985 secs\n",
      "iter:43,lower_bound:-34545649.501399,duration:85.814631 secs\n",
      "iter:44,lower_bound:-34545591.483010,duration:85.684439 secs\n",
      "iter:45,lower_bound:-34545545.264708,duration:84.779005 secs\n",
      "iter:46,lower_bound:-34545507.963263,duration:85.480198 secs\n",
      "iter:47,lower_bound:-34545462.901589,duration:85.876360 secs\n",
      "iter:48,lower_bound:-34545427.823699,duration:85.402862 secs\n",
      "iter:49,lower_bound:-34545392.151535,duration:85.614895 secs\n"
     ]
    }
   ],
   "source": [
    "lower_bounds_2 = multinomial_mixture_model.fit(documents, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in lower_bounds_1:\n",
    "    lower_bounds.append(l)\n",
    "\n",
    "for l in lower_bounds_2:\n",
    "    lower_bounds.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq8AAAIHCAYAAACxLrUeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f90b866e590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = subplots(1,1, figsize = (8, 6))\n",
    "f[1].plot(lower_bounds);\n",
    "f[1].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Collapsed Gibbs Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DocumentWithCluster:\n",
    "    def __init__(self, doc):\n",
    "        self.doc = doc\n",
    "        self.topic_index = 0\n",
    "\n",
    "document_with_cluster_list = [DocumentWithCluster(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CollapsedGibbsSampler:\n",
    "    def __init__(self, num_clusters, vocabulary_size, mixing_proportions_prior, topic_prior):\n",
    "        self.num_clusters = num_clusters\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.mixing_proportions_prior = mixing_proportions_prior\n",
    "        self.topic_prior = topic_prior\n",
    "        self.wordCountByWordAndFactor = np.zeros((vocabulary_size, num_clusters), dtype=np.int32)\n",
    "        self.wordCountByFactor = np.zeros(num_clusters, dtype=np.int32)\n",
    "        self.documentCountByFactor = np.zeros(num_clusters, dtype=np.int32)\n",
    "        self.training_lik = 0\n",
    "        self.complete_conditional = np.zeros(num_clusters)\n",
    "        self.vb = topic_prior * vocabulary_size\n",
    "        \n",
    "    def initialize(self, document_with_cluster_list):\n",
    "        for document_with_cluster in document_with_cluster_list:\n",
    "            document_with_cluster.topic_index = np.random.choice(self.num_clusters, 1)[0]\n",
    "            \n",
    "            self.wordCountByWordAndFactor[document_with_cluster.doc, document_with_cluster.topic_index] += 1\n",
    "            self.wordCountByFactor[document_with_cluster.topic_index] += len(document_with_cluster.doc)\n",
    "            self.documentCountByFactor[document_with_cluster.topic_index] += 1\n",
    "            \n",
    "    def sample_from_complete_conditional_for_topic_for_doc(self, doc):\n",
    "        ll = np.ones(self.num_clusters)\n",
    "        cumulative_log_scale = 0\n",
    "        for v in doc:\n",
    "            ll *= (self.wordCountByWordAndFactor[v, :] + self.topic_prior) / (self.wordCountByFactor + self.vb)\n",
    "            scale = max(ll)\n",
    "            cumulative_log_scale += np.log(scale)\n",
    "            ll /= scale\n",
    "            \n",
    "        self.complete_conditional = ll * (self.documentCountByFactor + self.mixing_proportions_prior)\n",
    "        normalizer = self.complete_conditional.sum()\n",
    "        self.complete_conditional /= normalizer\n",
    "        topic_index = np.random.choice(self.num_clusters, 1, replace = False, p = self.complete_conditional)[0]\n",
    "        self.training_lik += np.log(normalizer) + cumulative_log_scale\n",
    "        return topic_index\n",
    "    \n",
    "    def run_sampler(self, document_with_cluster_list, max_iterations):\n",
    "        for iteration in np.arange(max_iterations):\n",
    "            self.training_lik = 0\n",
    "            total_obs = 0\n",
    "            start = time.time()\n",
    "\n",
    "            for document_with_cluster in document_with_cluster_list:\n",
    "                \n",
    "                self.wordCountByWordAndFactor[document_with_cluster.doc, document_with_cluster.topic_index] -= 1\n",
    "                self.wordCountByFactor[document_with_cluster.topic_index] -= len(document_with_cluster.doc)\n",
    "                self.documentCountByFactor[document_with_cluster.topic_index] -= 1\n",
    "                \n",
    "                document_with_cluster.topic_index = self.sample_from_complete_conditional_for_topic_for_doc(document_with_cluster.doc)\n",
    "                \n",
    "                self.wordCountByWordAndFactor[document_with_cluster.doc, document_with_cluster.topic_index] += 1\n",
    "                self.wordCountByFactor[document_with_cluster.topic_index] += len(document_with_cluster.doc)\n",
    "                self.documentCountByFactor[document_with_cluster.topic_index] += 1\n",
    "                \n",
    "                total_obs += len(document_with_cluster.doc)\n",
    "            \n",
    "            end = time.time()\n",
    "            duration = end - start\n",
    "            print 'iter:%s,trainingLL:%.4f,duration:%.4f secs' % (iteration, self.training_lik / total_obs, duration)\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gibbs_sampler = CollapsedGibbsSampler(num_clusters=100,\n",
    "                                      vocabulary_size=len(vocabulary),\n",
    "                                      mixing_proportions_prior = 0.01,\n",
    "                                      topic_prior = 0.01)\n",
    "gibbs_sampler.initialize(document_with_cluster_list=document_with_cluster_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0,trainingLL:-7.1174,duration:119.3286 secs\n",
      "iter:1,trainingLL:-7.0044,duration:119.8174 secs\n",
      "iter:2,trainingLL:-6.9788,duration:120.0058 secs\n",
      "iter:3,trainingLL:-6.9668,duration:120.1556 secs\n",
      "iter:4,trainingLL:-6.9602,duration:120.1897 secs\n",
      "iter:5,trainingLL:-6.9554,duration:119.9911 secs\n",
      "iter:6,trainingLL:-6.9524,duration:120.0445 secs\n",
      "iter:7,trainingLL:-6.9505,duration:120.5137 secs\n",
      "iter:8,trainingLL:-6.9494,duration:120.7709 secs\n",
      "iter:9,trainingLL:-6.9488,duration:120.3573 secs\n",
      "iter:10,trainingLL:-6.9483,duration:120.4899 secs\n",
      "iter:11,trainingLL:-6.9479,duration:120.6922 secs\n",
      "iter:12,trainingLL:-6.9476,duration:120.4757 secs\n",
      "iter:13,trainingLL:-6.9473,duration:120.4348 secs\n",
      "iter:14,trainingLL:-6.9471,duration:120.9466 secs\n",
      "iter:15,trainingLL:-6.9469,duration:121.0840 secs\n",
      "iter:16,trainingLL:-6.9467,duration:120.9786 secs\n",
      "iter:17,trainingLL:-6.9467,duration:120.7265 secs\n",
      "iter:18,trainingLL:-6.9466,duration:120.6130 secs\n",
      "iter:19,trainingLL:-6.9465,duration:120.7785 secs\n",
      "iter:20,trainingLL:-6.9464,duration:121.1221 secs\n",
      "iter:21,trainingLL:-6.9462,duration:120.4588 secs\n",
      "iter:22,trainingLL:-6.9461,duration:120.2546 secs\n",
      "iter:23,trainingLL:-6.9460,duration:120.7767 secs\n",
      "iter:24,trainingLL:-6.9459,duration:120.2040 secs\n",
      "iter:25,trainingLL:-6.9458,duration:122.9215 secs\n",
      "iter:26,trainingLL:-6.9457,duration:122.2840 secs\n",
      "iter:27,trainingLL:-6.9456,duration:123.1995 secs\n",
      "iter:28,trainingLL:-6.9455,duration:123.4737 secs\n",
      "iter:29,trainingLL:-6.9454,duration:127.6076 secs\n",
      "iter:30,trainingLL:-6.9452,duration:122.8721 secs\n",
      "iter:31,trainingLL:-6.9451,duration:129.4701 secs\n",
      "iter:32,trainingLL:-6.9452,duration:124.7582 secs\n",
      "iter:33,trainingLL:-6.9451,duration:134.3089 secs\n",
      "iter:34,trainingLL:-6.9451,duration:149.9578 secs\n",
      "iter:35,trainingLL:-6.9451,duration:146.3645 secs\n",
      "iter:36,trainingLL:-6.9450,duration:148.6202 secs\n",
      "iter:37,trainingLL:-6.9450,duration:149.8051 secs\n",
      "iter:38,trainingLL:-6.9450,duration:156.1286 secs\n",
      "iter:39,trainingLL:-6.9450,duration:152.3959 secs\n",
      "iter:40,trainingLL:-6.9450,duration:148.6415 secs\n",
      "iter:41,trainingLL:-6.9450,duration:148.4366 secs\n",
      "iter:42,trainingLL:-6.9449,duration:151.4360 secs\n",
      "iter:43,trainingLL:-6.9449,duration:152.0117 secs\n",
      "iter:44,trainingLL:-6.9449,duration:151.4203 secs\n",
      "iter:45,trainingLL:-6.9449,duration:146.6499 secs\n",
      "iter:46,trainingLL:-6.9449,duration:144.7154 secs\n",
      "iter:47,trainingLL:-6.9449,duration:149.3171 secs\n",
      "iter:48,trainingLL:-6.9448,duration:144.3285 secs\n",
      "iter:49,trainingLL:-6.9448,duration:139.0492 secs\n",
      "iter:50,trainingLL:-6.9448,duration:136.0321 secs\n",
      "iter:51,trainingLL:-6.9449,duration:128.6989 secs\n",
      "iter:52,trainingLL:-6.9449,duration:128.7114 secs\n",
      "iter:53,trainingLL:-6.9449,duration:124.7435 secs\n",
      "iter:54,trainingLL:-6.9449,duration:125.4185 secs\n",
      "iter:55,trainingLL:-6.9449,duration:128.4914 secs\n",
      "iter:56,trainingLL:-6.9448,duration:124.1818 secs\n",
      "iter:57,trainingLL:-6.9448,duration:130.5856 secs\n",
      "iter:58,trainingLL:-6.9448,duration:123.1010 secs\n",
      "iter:59,trainingLL:-6.9448,duration:125.0687 secs\n",
      "iter:60,trainingLL:-6.9448,duration:126.8477 secs\n",
      "iter:61,trainingLL:-6.9448,duration:129.9470 secs\n",
      "iter:62,trainingLL:-6.9447,duration:131.8870 secs\n",
      "iter:63,trainingLL:-6.9447,duration:132.9128 secs\n",
      "iter:64,trainingLL:-6.9447,duration:143.0118 secs\n",
      "iter:65,trainingLL:-6.9447,duration:142.9356 secs\n",
      "iter:66,trainingLL:-6.9447,duration:145.0146 secs\n",
      "iter:67,trainingLL:-6.9447,duration:139.7520 secs\n",
      "iter:68,trainingLL:-6.9447,duration:138.0820 secs\n",
      "iter:69,trainingLL:-6.9446,duration:131.6363 secs\n",
      "iter:70,trainingLL:-6.9446,duration:140.3236 secs\n",
      "iter:71,trainingLL:-6.9446,duration:137.9255 secs\n",
      "iter:72,trainingLL:-6.9446,duration:141.4424 secs\n",
      "iter:73,trainingLL:-6.9446,duration:137.3049 secs\n",
      "iter:74,trainingLL:-6.9446,duration:133.6330 secs\n",
      "iter:75,trainingLL:-6.9445,duration:134.4285 secs\n",
      "iter:76,trainingLL:-6.9445,duration:133.3915 secs\n",
      "iter:77,trainingLL:-6.9445,duration:134.6677 secs\n",
      "iter:78,trainingLL:-6.9445,duration:140.6792 secs\n",
      "iter:79,trainingLL:-6.9445,duration:137.4028 secs\n",
      "iter:80,trainingLL:-6.9444,duration:134.7962 secs\n",
      "iter:81,trainingLL:-6.9444,duration:155.1483 secs\n",
      "iter:82,trainingLL:-6.9444,duration:172.1374 secs\n",
      "iter:83,trainingLL:-6.9444,duration:146.3972 secs\n",
      "iter:84,trainingLL:-6.9444,duration:131.2712 secs\n",
      "iter:85,trainingLL:-6.9444,duration:126.5259 secs\n",
      "iter:86,trainingLL:-6.9444,duration:123.7933 secs\n",
      "iter:87,trainingLL:-6.9444,duration:122.0677 secs\n",
      "iter:88,trainingLL:-6.9444,duration:121.6322 secs\n",
      "iter:89,trainingLL:-6.9444,duration:122.6422 secs\n",
      "iter:90,trainingLL:-6.9444,duration:122.3369 secs\n",
      "iter:91,trainingLL:-6.9445,duration:122.2644 secs\n",
      "iter:92,trainingLL:-6.9444,duration:126.8057 secs\n",
      "iter:93,trainingLL:-6.9444,duration:129.0219 secs\n",
      "iter:94,trainingLL:-6.9445,duration:121.6462 secs\n",
      "iter:95,trainingLL:-6.9444,duration:123.0667 secs\n",
      "iter:96,trainingLL:-6.9444,duration:126.6448 secs\n",
      "iter:97,trainingLL:-6.9444,duration:126.2046 secs\n",
      "iter:98,trainingLL:-6.9444,duration:124.7500 secs\n",
      "iter:99,trainingLL:-6.9444,duration:124.2390 secs\n"
     ]
    }
   ],
   "source": [
    "gibbs_sampler.run_sampler(document_with_cluster_list = document_with_cluster_list, max_iterations = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Stochastic Variational Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.special import psi as digamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StochasticVariationalInference :\n",
    "    def __init__(self, num_documents, num_clusters, vocabulary_size, mini_batch_size, h_beta, h_theta):\n",
    "        avg_words_per_doc = 50.\n",
    "        self.v_beta_agg = np.random.exponential(num_documents * avg_words_per_doc / (vocabulary_size * num_clusters), (vocabulary_size, num_clusters))\n",
    "        self.v_theta_agg = np.random.exponential(num_documents * 1.0 / num_clusters, num_clusters)\n",
    "\n",
    "        self.v_beta_exp = digamma(self.v_beta_agg + h_beta)\n",
    "        self.v_theta_exp = digamma(self.v_theta_agg + h_theta) - digamma((self.v_theta_agg + h_theta).sum())\n",
    "        temp = digamma((self.v_beta_agg + h_beta).sum(0))\n",
    "        for w in np.arange(vocabulary_size):\n",
    "            self.v_beta_exp[w, :] -= temp\n",
    "\n",
    "\n",
    "        self.num_clusters = num_clusters\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.h_theta = h_theta\n",
    "        self.h_beta = h_beta\n",
    "        self.training_ll = 0\n",
    "\n",
    "    def compute_multinomial_responsibilities(self, doc):\n",
    "\n",
    "        q_zn = np.zeros(self.num_clusters)\n",
    "        q_zn += self.v_theta_exp\n",
    "\n",
    "        for v in doc:\n",
    "            q_zn += self.v_beta_exp[v, :]\n",
    "        cumulative_log_scale = max(q_zn)\n",
    "        q_zn -= cumulative_log_scale\n",
    "        q_zn = np.exp(q_zn)\n",
    "        normalizer = q_zn.sum()\n",
    "        self.training_ll += cumulative_log_scale + np.log(normalizer)\n",
    "        return q_zn / normalizer\n",
    "\n",
    "    def fit(self, documents, max_iter):\n",
    "        beta_aggregates = np.zeros((self.vocabulary_size, self.num_clusters))\n",
    "        theta_aggregates = np.zeros(self.num_clusters)\n",
    "        forgetting_rate = 0.7\n",
    "        delay = 2\n",
    "        for iteration in range(max_iter):\n",
    "            learning_rate_t = np.power((iteration + delay), -1 * forgetting_rate)\n",
    "            self.training_ll = 0\n",
    "            beta_aggregates *= 0\n",
    "            theta_aggregates *= 0\n",
    "            start = time.time()\n",
    "            total_obs = 0\n",
    "            mini_batch_indices = rnd.sample(np.arange(len(documents)), self.mini_batch_size)\n",
    "            for ind in mini_batch_indices:\n",
    "                doc = documents[ind]\n",
    "                q_zn = self.compute_multinomial_responsibilities(doc)\n",
    "                beta_aggregates[doc, :] += q_zn\n",
    "                theta_aggregates += q_zn\n",
    "                total_obs += len(doc)\n",
    "\n",
    "            ll_thickening_factor = len(documents) * 1.0 / len(mini_batch_indices)\n",
    "            \n",
    "            self.v_beta_agg = (1 - learning_rate_t) * self.v_beta_agg + learning_rate_t * ll_thickening_factor * beta_aggregates\n",
    "            self.v_beta_exp = digamma(self.v_beta_agg + self.h_beta)\n",
    "            temp = digamma((self.v_beta_agg + self.h_beta).sum(0))\n",
    "            for w in np.arange(self.vocabulary_size):\n",
    "                self.v_beta_exp[w, :] -= temp\n",
    "\n",
    "            self.v_theta_agg = (1 - learning_rate_t) * self.v_theta_agg + learning_rate_t * ll_thickening_factor * theta_aggregates + self.h_theta\n",
    "            self.v_theta_exp = digamma(self.v_theta_agg + self.h_theta) - digamma((self.v_theta_agg + self.h_theta).sum())\n",
    "\n",
    "            end = time.time()\n",
    "            duration = end - start\n",
    "            print 'iter:%d,training_ll:%f,learning_rate:%f,duration:%f secs'%(iteration, self.training_ll / total_obs,learning_rate_t,duration)\n",
    "            sys.stdout.flush()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svi = StochasticVariationalInference(num_documents = len(documents),\n",
    "                                     num_clusters = 100,\n",
    "                                     vocabulary_size = len(vocabulary),\n",
    "                                     mini_batch_size = 5000,\n",
    "                                     h_beta = 0.01,\n",
    "                                     h_theta = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0,training_ll:-9.033846,learning_rate:0.615572,duration:1.859016 secs\n",
      "iter:1,training_ll:-7.835030,learning_rate:0.463463,duration:2.220320 secs\n",
      "iter:2,training_ll:-7.525486,learning_rate:0.378929,duration:2.331630 secs\n",
      "iter:3,training_ll:-7.421320,learning_rate:0.324131,duration:2.181140 secs\n",
      "iter:4,training_ll:-7.381935,learning_rate:0.285295,duration:1.919822 secs\n",
      "iter:5,training_ll:-7.357037,learning_rate:0.256113,duration:1.834947 secs\n",
      "iter:6,training_ll:-7.355625,learning_rate:0.233258,duration:1.712588 secs\n",
      "iter:7,training_ll:-7.343074,learning_rate:0.214798,duration:1.577381 secs\n",
      "iter:8,training_ll:-7.346145,learning_rate:0.199526,duration:1.370758 secs\n",
      "iter:9,training_ll:-7.329162,learning_rate:0.186649,duration:1.208718 secs\n",
      "iter:10,training_ll:-7.321702,learning_rate:0.175620,duration:1.145792 secs\n",
      "iter:11,training_ll:-7.302745,learning_rate:0.166050,duration:1.078139 secs\n",
      "iter:12,training_ll:-7.307825,learning_rate:0.157656,duration:1.032471 secs\n",
      "iter:13,training_ll:-7.331498,learning_rate:0.150223,duration:1.008851 secs\n",
      "iter:14,training_ll:-7.300283,learning_rate:0.143587,duration:0.972244 secs\n",
      "iter:15,training_ll:-7.295576,learning_rate:0.137621,duration:0.939232 secs\n",
      "iter:16,training_ll:-7.323787,learning_rate:0.132224,duration:0.928062 secs\n",
      "iter:17,training_ll:-7.320431,learning_rate:0.127313,duration:0.909618 secs\n",
      "iter:18,training_ll:-7.299346,learning_rate:0.122823,duration:0.884426 secs\n",
      "iter:19,training_ll:-7.286619,learning_rate:0.118699,duration:0.870167 secs\n",
      "iter:20,training_ll:-7.288399,learning_rate:0.114896,duration:0.893141 secs\n",
      "iter:21,training_ll:-7.299823,learning_rate:0.111376,duration:0.865513 secs\n",
      "iter:22,training_ll:-7.309364,learning_rate:0.108107,duration:0.870391 secs\n",
      "iter:23,training_ll:-7.303360,learning_rate:0.105061,duration:0.845150 secs\n",
      "iter:24,training_ll:-7.289208,learning_rate:0.102216,duration:0.844237 secs\n",
      "iter:25,training_ll:-7.288846,learning_rate:0.099551,duration:0.832108 secs\n",
      "iter:26,training_ll:-7.275276,learning_rate:0.097049,duration:0.827770 secs\n",
      "iter:27,training_ll:-7.287318,learning_rate:0.094694,duration:0.816177 secs\n",
      "iter:28,training_ll:-7.305530,learning_rate:0.092473,duration:0.843041 secs\n",
      "iter:29,training_ll:-7.294873,learning_rate:0.090375,duration:0.829702 secs\n",
      "iter:30,training_ll:-7.292432,learning_rate:0.088388,duration:0.833871 secs\n",
      "iter:31,training_ll:-7.309984,learning_rate:0.086505,duration:0.848014 secs\n",
      "iter:32,training_ll:-7.294306,learning_rate:0.084716,duration:0.832584 secs\n",
      "iter:33,training_ll:-7.287658,learning_rate:0.083014,duration:0.821140 secs\n",
      "iter:34,training_ll:-7.283538,learning_rate:0.081393,duration:0.803072 secs\n",
      "iter:35,training_ll:-7.313605,learning_rate:0.079847,duration:0.810859 secs\n",
      "iter:36,training_ll:-7.308416,learning_rate:0.078370,duration:0.810142 secs\n",
      "iter:37,training_ll:-7.305016,learning_rate:0.076958,duration:0.811417 secs\n",
      "iter:38,training_ll:-7.282296,learning_rate:0.075606,duration:0.809380 secs\n",
      "iter:39,training_ll:-7.297500,learning_rate:0.074311,duration:0.823185 secs\n",
      "iter:40,training_ll:-7.310824,learning_rate:0.073068,duration:0.830837 secs\n",
      "iter:41,training_ll:-7.283871,learning_rate:0.071874,duration:0.812251 secs\n",
      "iter:42,training_ll:-7.289256,learning_rate:0.070727,duration:0.809523 secs\n",
      "iter:43,training_ll:-7.297003,learning_rate:0.069623,duration:0.806963 secs\n",
      "iter:44,training_ll:-7.284938,learning_rate:0.068560,duration:0.828209 secs\n",
      "iter:45,training_ll:-7.293319,learning_rate:0.067535,duration:0.819315 secs\n",
      "iter:46,training_ll:-7.303047,learning_rate:0.066547,duration:0.831826 secs\n",
      "iter:47,training_ll:-7.249203,learning_rate:0.065594,duration:0.810763 secs\n",
      "iter:48,training_ll:-7.280264,learning_rate:0.064673,duration:0.802240 secs\n",
      "iter:49,training_ll:-7.307238,learning_rate:0.063782,duration:0.804820 secs\n",
      "iter:50,training_ll:-7.289896,learning_rate:0.062921,duration:0.804718 secs\n",
      "iter:51,training_ll:-7.298596,learning_rate:0.062088,duration:0.817292 secs\n",
      "iter:52,training_ll:-7.275867,learning_rate:0.061281,duration:0.802939 secs\n",
      "iter:53,training_ll:-7.267525,learning_rate:0.060499,duration:0.801119 secs\n",
      "iter:54,training_ll:-7.306762,learning_rate:0.059740,duration:0.804287 secs\n",
      "iter:55,training_ll:-7.281032,learning_rate:0.059005,duration:0.793859 secs\n",
      "iter:56,training_ll:-7.274118,learning_rate:0.058291,duration:0.791650 secs\n",
      "iter:57,training_ll:-7.297202,learning_rate:0.057597,duration:0.788927 secs\n",
      "iter:58,training_ll:-7.299515,learning_rate:0.056924,duration:0.800466 secs\n",
      "iter:59,training_ll:-7.274770,learning_rate:0.056269,duration:0.801632 secs\n",
      "iter:60,training_ll:-7.290050,learning_rate:0.055632,duration:0.799980 secs\n",
      "iter:61,training_ll:-7.307771,learning_rate:0.055013,duration:0.820386 secs\n",
      "iter:62,training_ll:-7.292127,learning_rate:0.054409,duration:0.810585 secs\n",
      "iter:63,training_ll:-7.280427,learning_rate:0.053822,duration:0.806481 secs\n",
      "iter:64,training_ll:-7.282560,learning_rate:0.053250,duration:0.809987 secs\n",
      "iter:65,training_ll:-7.296800,learning_rate:0.052692,duration:0.804779 secs\n",
      "iter:66,training_ll:-7.278316,learning_rate:0.052149,duration:0.806429 secs\n",
      "iter:67,training_ll:-7.284907,learning_rate:0.051619,duration:0.812094 secs\n",
      "iter:68,training_ll:-7.290727,learning_rate:0.051101,duration:0.804692 secs\n",
      "iter:69,training_ll:-7.313625,learning_rate:0.050596,duration:0.812160 secs\n",
      "iter:70,training_ll:-7.284713,learning_rate:0.050103,duration:0.809598 secs\n",
      "iter:71,training_ll:-7.276196,learning_rate:0.049622,duration:0.806862 secs\n",
      "iter:72,training_ll:-7.274614,learning_rate:0.049152,duration:0.813688 secs\n",
      "iter:73,training_ll:-7.295229,learning_rate:0.048692,duration:0.801657 secs\n",
      "iter:74,training_ll:-7.283495,learning_rate:0.048243,duration:0.812117 secs\n",
      "iter:75,training_ll:-7.273909,learning_rate:0.047803,duration:0.802673 secs\n",
      "iter:76,training_ll:-7.290467,learning_rate:0.047373,duration:0.801427 secs\n",
      "iter:77,training_ll:-7.281386,learning_rate:0.046953,duration:0.805624 secs\n",
      "iter:78,training_ll:-7.276122,learning_rate:0.046541,duration:0.808149 secs\n",
      "iter:79,training_ll:-7.291398,learning_rate:0.046138,duration:0.805773 secs\n",
      "iter:80,training_ll:-7.305451,learning_rate:0.045744,duration:0.805082 secs\n",
      "iter:81,training_ll:-7.274530,learning_rate:0.045357,duration:0.796288 secs\n",
      "iter:82,training_ll:-7.272072,learning_rate:0.044978,duration:0.789189 secs\n",
      "iter:83,training_ll:-7.303841,learning_rate:0.044607,duration:0.798756 secs\n",
      "iter:84,training_ll:-7.272389,learning_rate:0.044244,duration:0.795500 secs\n",
      "iter:85,training_ll:-7.294623,learning_rate:0.043887,duration:0.789459 secs\n",
      "iter:86,training_ll:-7.304722,learning_rate:0.043537,duration:0.796243 secs\n",
      "iter:87,training_ll:-7.281671,learning_rate:0.043194,duration:0.799353 secs\n",
      "iter:88,training_ll:-7.298094,learning_rate:0.042858,duration:0.789591 secs\n",
      "iter:89,training_ll:-7.304770,learning_rate:0.042528,duration:0.799894 secs\n",
      "iter:90,training_ll:-7.306757,learning_rate:0.042204,duration:0.796972 secs\n",
      "iter:91,training_ll:-7.270410,learning_rate:0.041885,duration:0.790092 secs\n",
      "iter:92,training_ll:-7.277067,learning_rate:0.041573,duration:0.799992 secs\n",
      "iter:93,training_ll:-7.291256,learning_rate:0.041266,duration:0.793502 secs\n",
      "iter:94,training_ll:-7.284748,learning_rate:0.040965,duration:0.807170 secs\n",
      "iter:95,training_ll:-7.268875,learning_rate:0.040669,duration:0.790423 secs\n",
      "iter:96,training_ll:-7.287248,learning_rate:0.040378,duration:0.789320 secs\n",
      "iter:97,training_ll:-7.267609,learning_rate:0.040092,duration:0.798362 secs\n",
      "iter:98,training_ll:-7.256513,learning_rate:0.039811,duration:0.794172 secs\n",
      "iter:99,training_ll:-7.280778,learning_rate:0.039534,duration:0.792998 secs\n",
      "iter:100,training_ll:-7.293138,learning_rate:0.039263,duration:0.799159 secs\n",
      "iter:101,training_ll:-7.311272,learning_rate:0.038995,duration:0.800886 secs\n",
      "iter:102,training_ll:-7.270189,learning_rate:0.038733,duration:0.784773 secs\n",
      "iter:103,training_ll:-7.282506,learning_rate:0.038474,duration:0.785903 secs\n",
      "iter:104,training_ll:-7.273128,learning_rate:0.038220,duration:0.780445 secs\n",
      "iter:105,training_ll:-7.294143,learning_rate:0.037969,duration:0.787484 secs\n",
      "iter:106,training_ll:-7.276671,learning_rate:0.037723,duration:0.784874 secs\n",
      "iter:107,training_ll:-7.275147,learning_rate:0.037480,duration:0.783693 secs\n",
      "iter:108,training_ll:-7.276428,learning_rate:0.037241,duration:0.781674 secs\n",
      "iter:109,training_ll:-7.273187,learning_rate:0.037006,duration:0.790654 secs\n",
      "iter:110,training_ll:-7.271521,learning_rate:0.036775,duration:0.794958 secs\n",
      "iter:111,training_ll:-7.279227,learning_rate:0.036546,duration:0.798853 secs\n",
      "iter:112,training_ll:-7.276133,learning_rate:0.036322,duration:0.793106 secs\n",
      "iter:113,training_ll:-7.279995,learning_rate:0.036100,duration:0.785875 secs\n",
      "iter:114,training_ll:-7.280297,learning_rate:0.035882,duration:0.777476 secs\n",
      "iter:115,training_ll:-7.273722,learning_rate:0.035667,duration:0.781441 secs\n",
      "iter:116,training_ll:-7.290055,learning_rate:0.035455,duration:0.785294 secs\n",
      "iter:117,training_ll:-7.288881,learning_rate:0.035247,duration:0.775771 secs\n",
      "iter:118,training_ll:-7.299399,learning_rate:0.035041,duration:0.781133 secs\n",
      "iter:119,training_ll:-7.292669,learning_rate:0.034838,duration:0.798073 secs\n",
      "iter:120,training_ll:-7.276401,learning_rate:0.034638,duration:0.797847 secs\n",
      "iter:121,training_ll:-7.283593,learning_rate:0.034440,duration:0.797246 secs\n",
      "iter:122,training_ll:-7.276555,learning_rate:0.034246,duration:0.805367 secs\n",
      "iter:123,training_ll:-7.265444,learning_rate:0.034054,duration:0.797071 secs\n",
      "iter:124,training_ll:-7.284048,learning_rate:0.033864,duration:0.801653 secs\n",
      "iter:125,training_ll:-7.296999,learning_rate:0.033677,duration:0.804225 secs\n",
      "iter:126,training_ll:-7.275468,learning_rate:0.033493,duration:0.782260 secs\n",
      "iter:127,training_ll:-7.306647,learning_rate:0.033311,duration:0.799438 secs\n",
      "iter:128,training_ll:-7.299934,learning_rate:0.033131,duration:0.784459 secs\n",
      "iter:129,training_ll:-7.270610,learning_rate:0.032954,duration:0.783382 secs\n",
      "iter:130,training_ll:-7.301449,learning_rate:0.032779,duration:0.783456 secs\n",
      "iter:131,training_ll:-7.289644,learning_rate:0.032606,duration:0.789976 secs\n",
      "iter:132,training_ll:-7.294186,learning_rate:0.032436,duration:0.788508 secs\n",
      "iter:133,training_ll:-7.298647,learning_rate:0.032268,duration:0.790656 secs\n",
      "iter:134,training_ll:-7.294434,learning_rate:0.032101,duration:0.785464 secs\n",
      "iter:135,training_ll:-7.296784,learning_rate:0.031937,duration:0.788381 secs\n",
      "iter:136,training_ll:-7.309812,learning_rate:0.031775,duration:0.795816 secs\n",
      "iter:137,training_ll:-7.273135,learning_rate:0.031615,duration:0.791589 secs\n",
      "iter:138,training_ll:-7.264699,learning_rate:0.031456,duration:0.786974 secs\n",
      "iter:139,training_ll:-7.285035,learning_rate:0.031300,duration:0.796776 secs\n",
      "iter:140,training_ll:-7.284784,learning_rate:0.031146,duration:0.795863 secs\n",
      "iter:141,training_ll:-7.288162,learning_rate:0.030993,duration:0.785048 secs\n",
      "iter:142,training_ll:-7.285676,learning_rate:0.030842,duration:0.800196 secs\n",
      "iter:143,training_ll:-7.272244,learning_rate:0.030693,duration:0.782820 secs\n",
      "iter:144,training_ll:-7.293325,learning_rate:0.030546,duration:0.774429 secs\n",
      "iter:145,training_ll:-7.304049,learning_rate:0.030400,duration:0.793075 secs\n",
      "iter:146,training_ll:-7.275153,learning_rate:0.030256,duration:0.789024 secs\n",
      "iter:147,training_ll:-7.294093,learning_rate:0.030114,duration:0.784767 secs\n",
      "iter:148,training_ll:-7.304354,learning_rate:0.029973,duration:0.783958 secs\n",
      "iter:149,training_ll:-7.277444,learning_rate:0.029834,duration:0.778028 secs\n",
      "iter:150,training_ll:-7.262903,learning_rate:0.029697,duration:0.782601 secs\n",
      "iter:151,training_ll:-7.290443,learning_rate:0.029561,duration:0.779385 secs\n",
      "iter:152,training_ll:-7.297561,learning_rate:0.029426,duration:0.786346 secs\n",
      "iter:153,training_ll:-7.298082,learning_rate:0.029293,duration:0.798438 secs\n",
      "iter:154,training_ll:-7.265857,learning_rate:0.029162,duration:0.782887 secs\n",
      "iter:155,training_ll:-7.301264,learning_rate:0.029032,duration:0.793292 secs\n",
      "iter:156,training_ll:-7.277823,learning_rate:0.028903,duration:0.792679 secs\n",
      "iter:157,training_ll:-7.272137,learning_rate:0.028775,duration:0.794769 secs\n",
      "iter:158,training_ll:-7.298198,learning_rate:0.028649,duration:0.797903 secs\n",
      "iter:159,training_ll:-7.306721,learning_rate:0.028525,duration:0.803996 secs\n",
      "iter:160,training_ll:-7.266399,learning_rate:0.028401,duration:0.790217 secs\n",
      "iter:161,training_ll:-7.286717,learning_rate:0.028279,duration:0.791004 secs\n",
      "iter:162,training_ll:-7.286249,learning_rate:0.028158,duration:0.788621 secs\n",
      "iter:163,training_ll:-7.293109,learning_rate:0.028039,duration:0.793914 secs\n",
      "iter:164,training_ll:-7.279525,learning_rate:0.027921,duration:0.795375 secs\n",
      "iter:165,training_ll:-7.268502,learning_rate:0.027803,duration:0.777079 secs\n",
      "iter:166,training_ll:-7.288731,learning_rate:0.027687,duration:0.787051 secs\n",
      "iter:167,training_ll:-7.286993,learning_rate:0.027573,duration:0.778331 secs\n",
      "iter:168,training_ll:-7.261906,learning_rate:0.027459,duration:0.773654 secs\n",
      "iter:169,training_ll:-7.274636,learning_rate:0.027347,duration:0.765823 secs\n",
      "iter:170,training_ll:-7.286624,learning_rate:0.027235,duration:0.779233 secs\n",
      "iter:171,training_ll:-7.271718,learning_rate:0.027125,duration:0.781740 secs\n",
      "iter:172,training_ll:-7.285129,learning_rate:0.027016,duration:0.785519 secs\n",
      "iter:173,training_ll:-7.300176,learning_rate:0.026908,duration:0.788262 secs\n",
      "iter:174,training_ll:-7.276262,learning_rate:0.026800,duration:0.781178 secs\n",
      "iter:175,training_ll:-7.268001,learning_rate:0.026694,duration:0.783305 secs\n",
      "iter:176,training_ll:-7.291928,learning_rate:0.026589,duration:0.787504 secs\n",
      "iter:177,training_ll:-7.288228,learning_rate:0.026485,duration:0.776140 secs\n",
      "iter:178,training_ll:-7.277515,learning_rate:0.026382,duration:0.790798 secs\n",
      "iter:179,training_ll:-7.277231,learning_rate:0.026280,duration:0.775245 secs\n",
      "iter:180,training_ll:-7.281216,learning_rate:0.026179,duration:0.769703 secs\n",
      "iter:181,training_ll:-7.284394,learning_rate:0.026079,duration:0.791037 secs\n",
      "iter:182,training_ll:-7.267104,learning_rate:0.025979,duration:0.789338 secs\n",
      "iter:183,training_ll:-7.276677,learning_rate:0.025881,duration:0.777850 secs\n",
      "iter:184,training_ll:-7.291880,learning_rate:0.025783,duration:0.792321 secs\n",
      "iter:185,training_ll:-7.281989,learning_rate:0.025687,duration:0.786590 secs\n",
      "iter:186,training_ll:-7.273876,learning_rate:0.025591,duration:0.791736 secs\n",
      "iter:187,training_ll:-7.291085,learning_rate:0.025496,duration:0.795466 secs\n",
      "iter:188,training_ll:-7.281697,learning_rate:0.025402,duration:0.793277 secs\n",
      "iter:189,training_ll:-7.297524,learning_rate:0.025309,duration:0.785935 secs\n",
      "iter:190,training_ll:-7.284504,learning_rate:0.025217,duration:0.794675 secs\n",
      "iter:191,training_ll:-7.264462,learning_rate:0.025125,duration:0.779330 secs\n",
      "iter:192,training_ll:-7.242864,learning_rate:0.025034,duration:0.775806 secs\n",
      "iter:193,training_ll:-7.307671,learning_rate:0.024945,duration:0.783543 secs\n",
      "iter:194,training_ll:-7.298266,learning_rate:0.024855,duration:0.786825 secs\n",
      "iter:195,training_ll:-7.269797,learning_rate:0.024767,duration:0.778052 secs\n",
      "iter:196,training_ll:-7.316973,learning_rate:0.024679,duration:0.787224 secs\n",
      "iter:197,training_ll:-7.277779,learning_rate:0.024593,duration:0.783811 secs\n",
      "iter:198,training_ll:-7.299385,learning_rate:0.024506,duration:0.789729 secs\n",
      "iter:199,training_ll:-7.283298,learning_rate:0.024421,duration:0.775195 secs\n",
      "iter:200,training_ll:-7.272230,learning_rate:0.024336,duration:0.772077 secs\n",
      "iter:201,training_ll:-7.283035,learning_rate:0.024252,duration:0.784226 secs\n",
      "iter:202,training_ll:-7.289605,learning_rate:0.024169,duration:0.777500 secs\n",
      "iter:203,training_ll:-7.289301,learning_rate:0.024086,duration:0.795133 secs\n",
      "iter:204,training_ll:-7.296681,learning_rate:0.024005,duration:0.787999 secs\n",
      "iter:205,training_ll:-7.284639,learning_rate:0.023923,duration:0.787577 secs\n",
      "iter:206,training_ll:-7.279282,learning_rate:0.023843,duration:0.793751 secs\n",
      "iter:207,training_ll:-7.279308,learning_rate:0.023763,duration:0.771861 secs\n",
      "iter:208,training_ll:-7.269954,learning_rate:0.023684,duration:0.779671 secs\n",
      "iter:209,training_ll:-7.267186,learning_rate:0.023605,duration:0.785524 secs\n",
      "iter:210,training_ll:-7.282973,learning_rate:0.023527,duration:0.782054 secs\n",
      "iter:211,training_ll:-7.295387,learning_rate:0.023450,duration:0.804512 secs\n",
      "iter:212,training_ll:-7.294901,learning_rate:0.023373,duration:0.791759 secs\n",
      "iter:213,training_ll:-7.303198,learning_rate:0.023297,duration:0.787453 secs\n",
      "iter:214,training_ll:-7.294962,learning_rate:0.023221,duration:0.787455 secs\n",
      "iter:215,training_ll:-7.315163,learning_rate:0.023146,duration:0.789954 secs\n",
      "iter:216,training_ll:-7.291899,learning_rate:0.023072,duration:0.788005 secs\n",
      "iter:217,training_ll:-7.265241,learning_rate:0.022998,duration:0.779587 secs\n",
      "iter:218,training_ll:-7.298371,learning_rate:0.022925,duration:0.789029 secs\n",
      "iter:219,training_ll:-7.273969,learning_rate:0.022852,duration:0.794651 secs\n",
      "iter:220,training_ll:-7.313342,learning_rate:0.022780,duration:0.802366 secs\n",
      "iter:221,training_ll:-7.288138,learning_rate:0.022708,duration:0.783806 secs\n",
      "iter:222,training_ll:-7.291476,learning_rate:0.022637,duration:0.789473 secs\n",
      "iter:223,training_ll:-7.300416,learning_rate:0.022567,duration:0.790467 secs\n",
      "iter:224,training_ll:-7.271312,learning_rate:0.022497,duration:0.787164 secs\n",
      "iter:225,training_ll:-7.286586,learning_rate:0.022428,duration:0.785591 secs\n",
      "iter:226,training_ll:-7.296719,learning_rate:0.022359,duration:0.790402 secs\n",
      "iter:227,training_ll:-7.305946,learning_rate:0.022290,duration:0.794973 secs\n",
      "iter:228,training_ll:-7.277115,learning_rate:0.022222,duration:0.785130 secs\n",
      "iter:229,training_ll:-7.289560,learning_rate:0.022155,duration:0.784922 secs\n",
      "iter:230,training_ll:-7.275236,learning_rate:0.022088,duration:0.778721 secs\n",
      "iter:231,training_ll:-7.288019,learning_rate:0.022022,duration:0.786661 secs\n",
      "iter:232,training_ll:-7.304853,learning_rate:0.021956,duration:0.795081 secs\n",
      "iter:233,training_ll:-7.267899,learning_rate:0.021890,duration:0.792858 secs\n",
      "iter:234,training_ll:-7.276113,learning_rate:0.021825,duration:0.777228 secs\n",
      "iter:235,training_ll:-7.296597,learning_rate:0.021761,duration:0.788328 secs\n",
      "iter:236,training_ll:-7.277453,learning_rate:0.021697,duration:0.782084 secs\n",
      "iter:237,training_ll:-7.267762,learning_rate:0.021633,duration:0.774079 secs\n",
      "iter:238,training_ll:-7.289970,learning_rate:0.021570,duration:0.780404 secs\n",
      "iter:239,training_ll:-7.294039,learning_rate:0.021507,duration:0.779385 secs\n",
      "iter:240,training_ll:-7.299516,learning_rate:0.021445,duration:0.792704 secs\n",
      "iter:241,training_ll:-7.284233,learning_rate:0.021383,duration:0.779514 secs\n",
      "iter:242,training_ll:-7.293008,learning_rate:0.021322,duration:0.790126 secs\n",
      "iter:243,training_ll:-7.293486,learning_rate:0.021261,duration:0.784742 secs\n",
      "iter:244,training_ll:-7.310679,learning_rate:0.021200,duration:0.795754 secs\n",
      "iter:245,training_ll:-7.261390,learning_rate:0.021140,duration:0.781056 secs\n",
      "iter:246,training_ll:-7.286120,learning_rate:0.021081,duration:0.791545 secs\n",
      "iter:247,training_ll:-7.267900,learning_rate:0.021021,duration:0.779946 secs\n",
      "iter:248,training_ll:-7.281382,learning_rate:0.020962,duration:0.784689 secs\n",
      "iter:249,training_ll:-7.303016,learning_rate:0.020904,duration:0.777940 secs\n",
      "iter:250,training_ll:-7.289028,learning_rate:0.020846,duration:0.782483 secs\n",
      "iter:251,training_ll:-7.290382,learning_rate:0.020788,duration:0.779846 secs\n",
      "iter:252,training_ll:-7.273887,learning_rate:0.020731,duration:0.788557 secs\n",
      "iter:253,training_ll:-7.275080,learning_rate:0.020674,duration:0.771775 secs\n",
      "iter:254,training_ll:-7.293768,learning_rate:0.020617,duration:0.785870 secs\n",
      "iter:255,training_ll:-7.281317,learning_rate:0.020561,duration:0.771231 secs\n",
      "iter:256,training_ll:-7.267478,learning_rate:0.020505,duration:0.777731 secs\n",
      "iter:257,training_ll:-7.269165,learning_rate:0.020450,duration:0.778778 secs\n",
      "iter:258,training_ll:-7.284672,learning_rate:0.020395,duration:0.781028 secs\n",
      "iter:259,training_ll:-7.275128,learning_rate:0.020340,duration:0.773477 secs\n",
      "iter:260,training_ll:-7.307256,learning_rate:0.020286,duration:0.785927 secs\n",
      "iter:261,training_ll:-7.294662,learning_rate:0.020232,duration:0.769209 secs\n",
      "iter:262,training_ll:-7.305338,learning_rate:0.020178,duration:0.788444 secs\n",
      "iter:263,training_ll:-7.297287,learning_rate:0.020125,duration:0.783321 secs\n",
      "iter:264,training_ll:-7.272240,learning_rate:0.020072,duration:0.772953 secs\n",
      "iter:265,training_ll:-7.287807,learning_rate:0.020019,duration:0.785116 secs\n",
      "iter:266,training_ll:-7.277424,learning_rate:0.019967,duration:0.775396 secs\n",
      "iter:267,training_ll:-7.269816,learning_rate:0.019915,duration:0.771028 secs\n",
      "iter:268,training_ll:-7.282796,learning_rate:0.019863,duration:0.784694 secs\n",
      "iter:269,training_ll:-7.282041,learning_rate:0.019812,duration:0.774590 secs\n",
      "iter:270,training_ll:-7.294274,learning_rate:0.019761,duration:0.782705 secs\n",
      "iter:271,training_ll:-7.283147,learning_rate:0.019710,duration:0.781224 secs\n",
      "iter:272,training_ll:-7.278463,learning_rate:0.019660,duration:0.785118 secs\n",
      "iter:273,training_ll:-7.283321,learning_rate:0.019610,duration:0.770678 secs\n",
      "iter:274,training_ll:-7.285974,learning_rate:0.019560,duration:0.782985 secs\n",
      "iter:275,training_ll:-7.286784,learning_rate:0.019510,duration:0.784297 secs\n",
      "iter:276,training_ll:-7.286772,learning_rate:0.019461,duration:0.784059 secs\n",
      "iter:277,training_ll:-7.304410,learning_rate:0.019412,duration:0.785948 secs\n",
      "iter:278,training_ll:-7.275280,learning_rate:0.019364,duration:0.790039 secs\n",
      "iter:279,training_ll:-7.266160,learning_rate:0.019315,duration:0.773091 secs\n",
      "iter:280,training_ll:-7.291760,learning_rate:0.019268,duration:0.788170 secs\n",
      "iter:281,training_ll:-7.293812,learning_rate:0.019220,duration:0.785614 secs\n",
      "iter:282,training_ll:-7.271561,learning_rate:0.019172,duration:0.777527 secs\n",
      "iter:283,training_ll:-7.280631,learning_rate:0.019125,duration:0.774393 secs\n",
      "iter:284,training_ll:-7.282102,learning_rate:0.019078,duration:0.787377 secs\n",
      "iter:285,training_ll:-7.269330,learning_rate:0.019032,duration:0.787044 secs\n",
      "iter:286,training_ll:-7.275427,learning_rate:0.018986,duration:0.785975 secs\n",
      "iter:287,training_ll:-7.284546,learning_rate:0.018940,duration:0.784396 secs\n",
      "iter:288,training_ll:-7.257658,learning_rate:0.018894,duration:0.776910 secs\n",
      "iter:289,training_ll:-7.283486,learning_rate:0.018848,duration:0.778149 secs\n",
      "iter:290,training_ll:-7.311558,learning_rate:0.018803,duration:0.791211 secs\n",
      "iter:291,training_ll:-7.303051,learning_rate:0.018758,duration:0.792321 secs\n",
      "iter:292,training_ll:-7.273162,learning_rate:0.018714,duration:0.778500 secs\n",
      "iter:293,training_ll:-7.276098,learning_rate:0.018669,duration:0.777437 secs\n",
      "iter:294,training_ll:-7.297544,learning_rate:0.018625,duration:0.788577 secs\n",
      "iter:295,training_ll:-7.270062,learning_rate:0.018581,duration:0.779556 secs\n",
      "iter:296,training_ll:-7.280929,learning_rate:0.018537,duration:0.791978 secs\n",
      "iter:297,training_ll:-7.282717,learning_rate:0.018494,duration:0.795294 secs\n",
      "iter:298,training_ll:-7.295130,learning_rate:0.018451,duration:0.790807 secs\n",
      "iter:299,training_ll:-7.282688,learning_rate:0.018408,duration:0.786983 secs\n"
     ]
    }
   ],
   "source": [
    "svi.fit(documents, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
